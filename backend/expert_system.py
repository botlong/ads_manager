import sqlite3
import pandas as pd
from typing import List, Dict, Any, Tuple
from datetime import datetime, timedelta
import json

# --- Config & Helpers ---

DB_FILE = 'ads_data.sqlite' # Relative path assuming running from root or adjusted in usage

def get_db_connection():
    # Helper assuming this file is imported where DB_FILE is accessible or passed
    # For standalone, we define it here, but ideally we share with agent_service
    import os
    # Assuming running from D:\ads_manager
    db_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'ads_data.sqlite')
    return sqlite3.connect(db_path)

def query_db(query: str, params: tuple = ()) -> List[Dict[str, Any]]:
    conn = get_db_connection()
    conn.row_factory = sqlite3.Row
    try:
        cursor = conn.cursor()
        cursor.execute(query, params)
        rows = cursor.fetchall()
        return [dict(row) for row in rows]
    except Exception as e:
        print(f"DB Error in ExpertSystem: {e}")
        return []
    finally:
        conn.close()

# --- 1. ContextGuard (Risk Control) ---

# --- 1. ContextGuard (é£é™©æ§åˆ¶) ---

class ContextGuard:
    """
    é£é™©æ§åˆ¶å±‚ã€‚
    åŸºäºä¸šåŠ¡çº¦æŸï¼ˆå¦‚å¤§ä¿ƒã€å†·å¯åŠ¨ã€å­¦ä¹ æœŸï¼‰ä¸‹è°ƒæˆ–æ‹¦æˆªæ“ä½œå»ºè®®ã€‚
    """
    
    PROMOTION_PERIODS = [
        ('2025-11-20', '2025-12-05'), # é»‘äº”/ç½‘ç»œæ˜ŸæœŸä¸€ (BFCM)
        ('2026-06-01', '2026-06-20'), # 618 å¤§ä¿ƒ
    ]

    @staticmethod
    def check_risk(campaign_context: Dict[str, Any], target_date: str) -> Dict[str, Any]:
        """
        è¿”å›é£é™©è¯„ä¼°ç»“æœã€‚
        è¾“å‡º: { "status": "PASS" | "BLOCK" | "MARK", "reasons": [...] }
        """
        reasons = []
        status = "PASS"
        campaign_name = campaign_context.get('campaign', 'Unknown')
        
        # 1. å¤§ä¿ƒæœŸä¸é¢„çƒ­æœŸä¿æŠ¤ (Promotion & Lead-up)
        # é¢„çƒ­æœŸ: å¤§ä¿ƒå¼€å§‹å‰ 3 å¤©
        for start, end in ContextGuard.PROMOTION_PERIODS:
            start_dt = datetime.strptime(start, '%Y-%m-%d')
            target_dt = datetime.strptime(target_date, '%Y-%m-%d')
            lead_up_start = start_dt - timedelta(days=3)
            
            if start <= target_date <= end:
                status = "MARK"
                reasons.append(f"å¤„äºå¤§ä¿ƒæœŸé—´ ({start} è‡³ {end}) - è§¦å‘ä¿æŠ¤æœºåˆ¶ï¼Œå»ºè®®è§‚å¯Ÿã€‚")
            elif lead_up_start <= target_dt < start_dt:
                status = "MARK"
                reasons.append(f"å¤§ä¿ƒé¢„çƒ­æœŸ (å¤§ä¿ƒå°†äº {start} å¼€å§‹) - æ•°æ®å¯èƒ½å‰§çƒˆæ³¢åŠ¨ï¼Œä»…åšæ ‡è®°ã€‚")
        
        # 2. è°ƒä»·å†·å´æœŸä¿æŠ¤ (72H Budget Shift)
        # æŸ¥è¯¢è¿‡å» 3 å¤©çš„é¢„ç®—å†å²
        budget_query = """
            SELECT budget FROM campaign 
            WHERE campaign = ? AND date <= ? AND date >= date(?, '-3 days')
            ORDER BY date DESC
        """
        budgets = query_db(budget_query, (campaign_name, target_date, target_date))
        if budgets and len(budgets) >= 2:
            budget_values = [b['budget'] for b in budgets if b['budget'] is not None]
            if len(set(budget_values)) > 1:
                status = "MARK"
                reasons.append("è°ƒä»·å†·å´æœŸ: è¿‡å» 72 å°æ—¶å†…æ£€æµ‹åˆ°é¢„ç®—å˜åŠ¨ï¼Œæ•°æ®å°šæœªç¨³å®šï¼Œå»ºè®®ç»´æŒç°çŠ¶ã€‚")

        # 3. å†·å¯åŠ¨ / å­¦ä¹ æœŸä¿æŠ¤ (Cold Start / Learning Phase)
        query = """
            SELECT SUM(cost) as cost, SUM(conversions) as conv, COUNT(date) as days, MIN(date) as first_day
            FROM campaign
            WHERE campaign = ? AND date <= ?
        """
        res = query_db(query, (campaign_name, target_date))
        if res and res[0]['first_day'] is not None:
            stats = res[0]
            first_day_dt = datetime.strptime(stats['first_day'], '%Y-%m-%d')
            target_dt = datetime.strptime(target_date, '%Y-%m-%d')
            days_diff = (target_dt - first_day_dt).days
            
            if days_diff < 7:
                status = "BLOCK"
                reasons.append(f"å†·å¯åŠ¨ä¿æŠ¤: è¯¥ç³»åˆ—ä¸Šçº¿ä»… {days_diff + 1} å¤© (ä¸è¶³ 7 å¤©)ï¼Œä¸¥ç¦è¿›è¡Œå‰Šå‡æ“ä½œã€‚")
            elif (stats['conv'] or 0) < 30:
                 # å­¦ä¹ æœŸé€šå¸¸åˆ¤å®šä¸ºâ€œç³»ç»Ÿæç¤ºâ€è€Œéç¡¬æ€§é£é™©æ‹¦æˆª
                 reasons.append("è¿›å…¥å­¦ä¹ æœŸ: ç´¯è®¡è½¬åŒ–æ•° < 30ï¼Œç³»ç»Ÿä»åœ¨ä¼˜åŒ–äººç¾¤æ¨¡å‹ã€‚")

        return {"status": status, "reasons": reasons}

# --- 2. ExpertEngines (ç¡®å®šæ€§ä¸“å®¶è§„åˆ™) ---

class ExpertEngine:
    
    @staticmethod
    def search_term_expert(campaign_name: str, target_date: str) -> List[Dict]:
        """
        æœç´¢è¯ä¸“å®¶: è¯†åˆ«é«˜æŸè€—è¯ä¸åŒ¹é…è´¨é‡ä¸‹æ»‘
        """
        flags = []
        
        # 1. è·å–æœç´¢è¯æ•°æ® (äº¤äº’/ç‚¹å‡»å­—æ®µ: interactions, è½¬åŒ–å­—æ®µ: conversions)
        query = """
            SELECT search_term, match_type, SUM(cost) as cost, SUM(conversions) as conversions, SUM(interactions) as clicks
            FROM search_term
            WHERE campaign = ? AND date >= date(?, '-7 days')
            GROUP BY search_term, match_type
        """
        rows = query_db(query, (campaign_name, target_date))
        if not rows: return []
        
        total_cost = sum(r['cost'] for r in rows)
        if total_cost == 0: return []
        
        avg_cpa = 40.0 
        
        for r in rows:
            term = r['search_term'].lower()
            if any(brand in term for brand in ['brandname', 'google', 'official']):
                continue
                
            if r['cost'] > (avg_cpa * 1.5) and r['conversions'] == 0:
                flags.append({
                    "expert": "æœç´¢è¯ä¸“å®¶",
                    "issue": "é«˜æŸè€—æœç´¢è¯ (å»ºè®®æ’é™¤)",
                    "severity": "HIGH",
                    "evidence": f"æœç´¢è¯ '{r['search_term']}' åœ¨7å¤©å†…æ¶ˆè€— ${r['cost']:.0f} ä¸” 0 è½¬åŒ–ã€‚",
                    "suggestion": "æ·»åŠ ä¸ºå¦å®šå…³é”®è¯ã€‚"
                })
        
        broad_cost = sum(r['cost'] for r in rows if r['match_type'].lower() == 'broad')
        broad_share = broad_cost / total_cost
        if broad_share > 0.45:
             flags.append({
                "expert": "æœç´¢è¯ä¸“å®¶",
                "issue": "æµé‡åŒ¹é…è´¨é‡ä¸‹æ»‘",
                "severity": "MEDIUM",
                "evidence": f"å¹¿æ³›åŒ¹é…æ¶ˆè€—å æ¯”è¾¾ {broad_share*100:.1f}%ï¼Œå­˜åœ¨å¼•å…¥æ— å…³æµé‡é£é™©ã€‚",
                "suggestion": "æ£€æŸ¥æœç´¢è¯æ¡ç›®ï¼›è€ƒè™‘åˆ‡æ¢ä¸ºè¯ç»„åŒ¹é…æˆ–å®Œå…¨åŒ¹é…ä»¥ç²¾å‡†æ§åˆ¶ã€‚"
            })
            
        return flags

    @staticmethod
    def channel_expert(campaign_name: str, target_date: str) -> List[Dict]:
        """
        æ¸ é“ä¸“å®¶ (PMax): è¯†åˆ«æµé‡æ´—æ ·ä¸äº¤å‰è¡¥è´´
        """
        flags = []
        # Table: channel -> date, channels, status, campaigns, impr, clicks, interactions, conversions, conv_value, currency_code, cost, results, results_value, reports
        query = """
            SELECT channels, SUM(cost) as cost, SUM(results_value) as value, SUM(conversions) as conversions
            FROM channel
            WHERE campaigns = ? AND date >= date(?, '-7 days')
            GROUP BY channels
        """
        rows = query_db(query, (campaign_name, target_date))
        if not rows: return []
        
        total_cost = sum(r['cost'] for r in rows)
        total_value = sum(r['value'] for r in rows)
        camp_roas = total_value / total_cost if total_cost > 0 else 0
        
        channel_data = {r['channels']: r for r in rows}
        
        for ch in ['Display', 'Video']:
            if ch in channel_data:
                d = channel_data[ch]
                share = d['cost'] / total_cost
                ch_roas = d['value'] / d['cost'] if d['cost'] > 0 else 0
                if share > 0.35 and ch_roas < (camp_roas * 0.5):
                    flags.append({
                        "expert": "æ¸ é“ä¸“å®¶ (PMax)",
                        "issue": "ç³»ç»Ÿåˆ¤å®š: æµé‡æ´—æ · (Traffic Washing)",
                        "severity": "HIGH",
                        "evidence": f"{ch} æ¸ é“æ¶ˆè€—å æ¯”é«˜è¾¾ {share*100:.0f}%ï¼Œä½† ROAS ä»…ä¸º {ch_roas:.2f} (è¿œä½äºå‡å€¼)ã€‚",
                        "suggestion": "æ£€æŸ¥ç´ æèµ„æºç»„çš„äººç¾¤ä¿¡å·ï¼›è€ƒè™‘æ’é™¤ä½è´¨é‡å±•ç¤ºä½ã€‚"
                    })
        
        if 'Shopping' in channel_data:
            s = channel_data['Shopping']
            s_roas = s['value'] / s['cost'] if s['cost'] > 0 else 0
            if s_roas > (camp_roas * 1.5):
                 flags.append({
                    "expert": "æ¸ é“ä¸“å®¶ (PMax)",
                    "issue": "ç³»ç»Ÿåˆ¤å®š: äº¤å‰è¡¥è´´ (Cross-Subsidy)",
                    "severity": "MEDIUM",
                    "evidence": f"Shopping æ¸ é“ ROAS ({s_roas:.2f}) æ©ç›–äº†å…¶ä»–æ¸ é“çš„äºæŸï¼Œæ•´ä½“æ•ˆç‡å—æŸã€‚",
                    "suggestion": "ä¼˜åŒ–æˆ–å‰Šå‡è½¬åŒ–ç‡ä½ä¸‹çš„éè´­ç‰©ç´ æç»„ã€‚"
                })

        return flags

    @staticmethod
    def product_expert(campaign_name: str, target_date: str) -> List[Dict]:
        """
        å•†å“ä¸“å®¶: è¯†åˆ«åƒµå°¸å•†å“ä¸é¢„ç®—å„æ–­
        """
        flags = []
        # Note: product ç¼ºå°‘ campaigns åˆ—ï¼Œè¿™é‡Œå¯èƒ½éœ€è¦è·³è¿‡æˆ–ä¼˜åŒ–é€»è¾‘
        # æš‚æ—¶åªæŸ¥è¯¢ product è¡¨ï¼Œç”±äºæ²¡æœ‰ campaign åˆ—ï¼Œè¿™é‡Œå¯èƒ½ä¼šè¿”å›ç©ºæˆ–å…¨é‡ï¼Œæ‰€ä»¥æˆ‘ä»¬åªèƒ½é€šè¿‡å…¶ä»–æ–¹å¼ã€‚
        # å¦‚æœ product è¡¨æ²¡æœ‰ campaign/campaigns åˆ—ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¶æ„ç¼ºé™·ã€‚
        # æˆ‘ä»¬æš‚æ—¶æ”¹ä¸ºè·å–å…¨é‡æ’åå‰ 10 çš„å•†å“ä½œä¸ºé£é™©æç¤ºã€‚
        query = """
            SELECT item_id, title, SUM(cost) as cost, SUM(clicks) as clicks
            FROM product
            WHERE date >= date(?, '-7 days')
            GROUP BY item_id
            ORDER BY cost DESC
            LIMIT 10
        """
        rows = query_db(query, (target_date,))
        if not rows: return []
        
        total_cost = sum(r['cost'] for r in rows)
        if total_cost == 0: return []

        if rows[0]['cost'] / total_cost > 0.85:
            flags.append({
                "expert": "å•†å“ä¸“å®¶",
                "issue": "é¢„ç®—å„æ–­ (å…¨å±€ Top å•†å“)",
                "severity": "MEDIUM",
                "evidence": f"å•å“ '{rows[0]['title']}' å æ®äº†ä¸»åŠ›é¢„ç®—ã€‚ (æ³¨: è¯¥è¡¨æ•°æ®æš‚ä¸æ”¯æŒæˆ˜å½¹çº§ä¸‹é’»)",
                "suggestion": "è€ƒè™‘ç›‘æ§è¯¥å•†å“åœ¨å„ç³»åˆ—çš„åˆ†é…ã€‚"
            })
            
        for r in rows:
            if r['cost'] > 100: # å¦‚æœæ¶ˆè€—å·¨å¤§ä½†ä¸çŸ¥é“è½¬åŒ–
                 flags.append({
                    "expert": "å•†å“ä¸“å®¶",
                    "issue": "é«˜æ¶ˆè€—å•†å“ (é¢„è­¦)",
                    "severity": "LOW",
                    "evidence": f"å•†å“ '{r['title']}' è¿‘7å¤©æ¶ˆè€— ${r['cost']:.0f}ã€‚",
                    "suggestion": "è¯·åœ¨ Google Ads åå°æ ¸å®è¯¥å•†å“çš„å®é™…è½¬åŒ–è¡¨ç°ã€‚"
                })
        return flags

    @staticmethod
    def keyword_expert(campaign_name: str, target_date: str) -> List[Dict]:
        """
        å…³é”®è¯ä¸“å®¶: è¯†åˆ«é«˜æŸè€—ä½ ROAS å…³é”®è¯
        """
        flags = []
        query = """
            SELECT keyword, match_type, SUM(cost) as cost, SUM(conversions) as conversions, SUM(conv_value) as value
            FROM keyword
            WHERE campaign = ? AND date >= date(?, '-14 days')
            GROUP BY keyword, match_type
            ORDER BY cost DESC
        """
        rows = query_db(query, (campaign_name, target_date))
        if not rows: return []
        
        for r in rows:
            roas = r['value'] / r['cost'] if r['cost'] > 0 else 0
            if r['cost'] > 50 and roas < 0.5:
                flags.append({
                    "expert": "å…³é”®è¯ä¸“å®¶",
                    "issue": "ä¸»å¹²è¯æŸè€—è¿‡å¤§",
                    "severity": "HIGH",
                    "evidence": f"å…³é”®è¯ '{r['keyword']}' æ¶ˆè€— ${r['cost']:.0f}ï¼Œä½† ROAS ä»…ä¸º {roas:.2f}ã€‚",
                    "suggestion": "æš‚åœè¯¥å…³é”®è¯æˆ–å¤§å¹…ä¸‹è°ƒå‡ºä»·ã€‚"
                })
        return flags

    @staticmethod
    def demographics_expert(campaign_name: str, table_name: str, target_date: str) -> List[Dict]:
        """
        äººå£ç»Ÿè®¡ä¸“å®¶ (å¹´é¾„/æ€§åˆ«): è¯†åˆ«ç»“æ„æ€§ä½æ•ˆ
        """
        flags = []
        col = 'age' if table_name == 'age' else 'gender'
        query = f"""
            SELECT {col}, SUM(cost) as cost, SUM(conversions) as conversions
            FROM {table_name}
            WHERE campaign = ? AND date >= date(?, '-30 days')
            GROUP BY {col}
        """
        rows = query_db(query, (campaign_name, target_date))
        if not rows: return []
        
        total_cost = sum(r['cost'] for r in rows)
        total_conv = sum(r['conversions'] for r in rows)
        if total_cost == 0: return []
        
        for r in rows:
            cpa = r['cost'] / r['conversions'] if r['conversions'] > 0 else (r['cost'] * 2) 
            avg_cpa = total_cost / total_conv if total_conv > 0 else 40.0
            
            if (r['cost'] / total_cost > 0.15) and (cpa > avg_cpa * 1.5):
                flags.append({
                    "expert": "äººå£ç»Ÿè®¡ä¸“å®¶",
                    "issue": f"{table_name} åˆ†å±‚æ•ˆç‡ä½ä¸‹",
                    "severity": "MEDIUM",
                    "evidence": f"'{r[col]}' åˆ†å±‚æ¶ˆè€—å æ¯” {r['cost']/total_cost*100:.0f}%ï¼ŒCPA é«˜äºå‡å€¼ 50% ä»¥ä¸Šã€‚",
                    "suggestion": "å¯¹æ­¤äººå£åˆ†å±‚åº”ç”¨è´Ÿå‡ºä»·è°ƒæ•´ (-50% æˆ–æ›´å¤š)ã€‚"
                })
        return flags

    @staticmethod
    def geo_expert(campaign_name: str, target_date: str) -> List[Dict]:
        """
        åœ°ç†ä½ç½®ä¸“å®¶: è¯†åˆ«åœ°ç†é»‘æ´
        """
        flags = []
        # Table: location_by_cities_all_campaign -> date, location, campaign, ...
        query = """
            SELECT location, SUM(cost) as cost, SUM(conversions) as conversions
            FROM location_by_cities_all_campaign
            WHERE campaign = ? AND date >= date(?, '-30 days')
            GROUP BY location
        """
        rows = query_db(query, (campaign_name, target_date))
        if not rows: return []
        
        for r in rows:
            if r['cost'] > 100 and r['conversions'] == 0:
                flags.append({
                    "expert": "åœ°ç†ä¸“å®¶",
                    "issue": "åœ°ç†é»‘æ´ (Geo Blackhole)",
                    "severity": "HIGH",
                    "evidence": f"åœ°åŒº '{r['location']}' åœ¨è¿‡å»30å¤©æ¶ˆè€— ${r['cost']:.0f} ä¸” 0 è½¬åŒ–ã€‚",
                    "suggestion": "æ’é™¤è¯¥åœ°ç†åŒºåŸŸä»¥èŠ‚çœé¢„ç®—ã€‚"
                })
        return flags

    @staticmethod
    def time_expert(campaign_name: str, target_date: str) -> List[Dict]:
        """
        åˆ†æ—¶ä¸“å®¶: è¯†åˆ«æŠ•æ”¾æ—¶æ®µå¼‚å¸¸
        """
        # Table 'time' is missing or has no schema, skip safely.
        return []

# --- 3. DiagnosisAggregator (è¯Šæ–­èšåˆå™¨) ---

class DiagnosisAggregator:
    
    @staticmethod
    def aggregate(campaign_name: str, trigger_info: Dict, expert_flags: List[Dict], context_status: Dict) -> Dict:
        """
        èšåˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Šã€‚
        """
        root_causes = []
        for f in expert_flags:
            if f['expert'] == 'æœç´¢è¯ä¸“å®¶': root_causes.append("æµé‡è´¨é‡ä¸‹æ»‘")
            if f['expert'] == 'å•†å“ä¸“å®¶': root_causes.append("ç»“æ„æ€§åˆ©æ¶¦é—®é¢˜")
            if f['expert'] == 'æ¸ é“ä¸“å®¶ (PMax)': root_causes.append("æ¸ é“æ´—æ ·/è¡¥è´´")
            if f['expert'] == 'åœ°ç†ä¸“å®¶': root_causes.append("åœ°ç†æŠ•æ”¾é»‘æ´")
            if f['expert'] == 'å…³é”®è¯ä¸“å®¶': root_causes.append("ä¸»è¯æµé‡æŸè€—")
        
        final_root_cause = " & ".join(list(set(root_causes))) if root_causes else "å®è§‚æ•ˆç‡æ³¢åŠ¨ (æœªå‘½ä¸­ç‰¹å®šè§„åˆ™)"

        # ç½®ä¿¡åº¦é€»è¾‘
        high_sev = any(f['severity'] == "HIGH" for f in expert_flags)
        if high_sev:
            confidence = "é«˜ (å‘½ä¸­æ ¸å¿ƒè§„åˆ™)"
        elif expert_flags:
            confidence = "ä¸­ (å­˜åœ¨å¯è§‚æµ‹æ¨¡å¼)"
        else:
            confidence = "ä½ (ä»…æœ‰è¶‹åŠ¿ä¿¡å·)"

        # æ‰§è¡ŒåŠ¨ä½œå»ºè®®æ ¸å¿ƒé€»è¾‘
        if context_status['status'] == 'BLOCK':
            action_level = "âœ‹ é£é™©æ‹¦æˆª (å†·å¯åŠ¨ä¿æŠ¤æœŸï¼Œä»…åšæ ‡è®°)"
        elif context_status['status'] == 'MARK':
            action_level = "âš ï¸ æ ‡è®°è§‚å¯Ÿ (å¤„äºè°ƒä»·æˆ–å¤§ä¿ƒé¢„çƒ­æœŸ)"
        elif high_sev:
            action_level = "ğŸš€ ç«‹å³ä¼˜åŒ– (å»ºè®®æ‰§è¡Œæ“ä½œ)"
        elif expert_flags:
            action_level = "ğŸ” æ·±åº¦è¯Šæ–­ (å»ºè®®è¯¦ç»†æ’æŸ¥æ•°æ®)"
        else:
            action_level = "ğŸ‘€ ä»…åšæ ‡è®° (æœªå‘½ä¸­ç‰¹å®šæ¨¡å¼)"

        coverage = 0.90 
        
        return {
            "campaign_name": campaign_name,
            "diagnosis": {
                "root_cause": final_root_cause,
                "confidence": confidence,
                "action_level": action_level,
                "triggered": trigger_info.get('triggered', False)
            },
            "flags": expert_flags,
            "trace_log": {
                "context": context_status,
                "coverage_ratio": coverage,
                "timestamp": datetime.now().isoformat()
            }
        }

